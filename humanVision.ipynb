{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # type: ignore #\n",
    "from tensorflow.keras.models import load_model #type: ignore #\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "modelPath = \"C:/Users/aahfa/Documents/personalCode/python/ML_AI/ML_NerfGun/relevantModels/humanIdentifyV1.h5\"\n",
    "model = load_model(modelPath)\n",
    "\n",
    "# Parameters\n",
    "img_height, img_width = 224, 224  \n",
    "threshold = 0.5\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#set frame size\n",
    "#cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "#cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    # Calculate absolute difference between frames\n",
    "    diff = cv2.absdiff(frame1, frame2) #takes two images and computes the difference between them. Returns\n",
    "    # an image where each pixel is the absolute difference between the two\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY) \n",
    "    # converts to gray scale, which streamlines computation\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # eliminates noise / small variations in image\n",
    "    placeHolder, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "    # Converts the image to binary form (black and white). Pixels with a value above 20 are set to 255 (white),\n",
    "    # and pixels with a value below or equal to 20 are set to 0 (black). This helps in clearly distinguishing the foreground \n",
    "    # (moving objects) from the background.\n",
    "    dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "    #dilates increase white region in image which disjointed white regions which makes the countours of detected\n",
    "    # moving objects more visible\n",
    "    contours, placeHolder = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #finds countours in the image\n",
    "\n",
    "    # Find the largest contour (assuming it's the human)\n",
    "    max_area = 0\n",
    "    xMin = float('inf')\n",
    "    yMin = float('inf')\n",
    "    xMax = float('-inf')\n",
    "    yMax = float('-inf')\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        xMin = min(xMin, x)\n",
    "        yMin = min(yMin, y)\n",
    "        xMax = max(xMax, x + w)\n",
    "        yMax = max(yMax, y + h)\n",
    "    \n",
    "    width = xMax - xMin\n",
    "    height = yMax - yMin\n",
    "\n",
    "    if(width > 0 and height > 0):\n",
    "        roi = frame1[yMin:yMin + height, xMin:xMin + width]\n",
    "        roi_resized = cv2.resize(roi, (img_height, img_width))\n",
    "        roi_normalized = roi_resized / 255.0\n",
    "        roi_expanded = np.expand_dims(roi_normalized, axis=0)\n",
    "\n",
    "        # Classify the region of interest\n",
    "        prediction = model.predict(roi_expanded)[0][0]\n",
    "        cv2.rectangle(frame1, (xMin, yMin), (xMin + width, yMin + height), (255, 0, 0), 2)\n",
    "        cv2.putText(frame1, f\"ROI\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        if prediction <= threshold:\n",
    "            cv2.rectangle(frame1, (xMin, yMin), (xMin + width, yMin + height), (0, 255, 0), 2)\n",
    "            cv2.putText(frame1, f\"Human: {prediction:.2f}\", (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame1)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
